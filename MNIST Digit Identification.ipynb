{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8775dc12",
   "metadata": {},
   "source": [
    "# Kenny Courser Summer 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1865b38c",
   "metadata": {},
   "source": [
    "## Find all the 9s!\n",
    "## 1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32def6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "546a682a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a085cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492eed98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70c3808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\AppData\\Local\\Temp\\ipykernel_10972\\1287233666.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = y.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Minkowski distance order 1:\n",
      "Number of 9s found: 1411\n",
      "Accuracy: 0.96\n",
      "Time taken: 183.9699 seconds\n",
      "-------------------------------------\n",
      "Results for Minkowski distance order 2:\n",
      "Number of 9s found: 1424\n",
      "Accuracy: 0.97\n",
      "Time taken: 14.7859 seconds\n",
      "-------------------------------------\n",
      "Results for Minkowski distance order 3:\n",
      "Number of 9s found: 1429\n",
      "Accuracy: 0.97\n",
      "Time taken: 2202.2709 seconds\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "X, y = mnist['data'], mnist['target']\n",
    "y = y.astype(np.int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Minkowski distance order for k-NN\n",
    "orders = [1, 2, 3]\n",
    "\n",
    "# Loop over each order and train k-NN model\n",
    "for order in orders:\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Train k-NN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=order)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Find all the 9s using the trained model\n",
    "    nines_indices = np.where(y_pred == 9)[0]\n",
    "    \n",
    "    # Calculate accuracy on the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    \n",
    "    # Calculate the time taken in seconds\n",
    "    time_taken = end_time - start_time\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for Minkowski distance order {order}:\")\n",
    "    print(f\"Number of 9s found: {len(nines_indices)}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Time taken: {time_taken:.4f} seconds\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e62fb0f",
   "metadata": {},
   "source": [
    "## 2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "961668b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision Tree:\n",
      "Number of 9s found: 1406\n",
      "Accuracy: 0.87\n",
      "Time taken: 16.5395 seconds\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "    \n",
    "# Train Decision Tree classifier\n",
    "dtree = DecisionTreeClassifier(max_depth=None)\n",
    "dtree.fit(X_train, y_train)\n",
    "    \n",
    "# Predict on the test set\n",
    "y_pred = dtree.predict(X_test)\n",
    "    \n",
    "# Find all the 9s using the trained model\n",
    "nines_indices = np.where(y_pred == 9)[0]\n",
    "    \n",
    "# Calculate accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "end_time = time.time()  # End timing\n",
    "    \n",
    "# Calculate the time taken in seconds\n",
    "time_taken = end_time - start_time\n",
    "    \n",
    "# Print the results\n",
    "print(f\"Results for Decision Tree:\")\n",
    "print(f\"Number of 9s found: {len(nines_indices)}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Time taken: {time_taken:.4f} seconds\")\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525bf325",
   "metadata": {},
   "source": [
    "## 3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2976ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "Number of 9s found: 1413\n",
      "Accuracy: 0.97\n",
      "Time taken: 49.7305 seconds\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "    \n",
    "# Train Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None)\n",
    "rf.fit(X_train, y_train)\n",
    "    \n",
    "# Predict on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "    \n",
    "# Find all the 9s using the trained model\n",
    "nines_indices = np.where(y_pred == 9)[0]\n",
    "    \n",
    "# Calculate accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "end_time = time.time()  # End timing\n",
    "    \n",
    "# Calculate the time taken in seconds\n",
    "time_taken = end_time - start_time\n",
    "    \n",
    "# Print the results\n",
    "print(f\"Results for Random Forest:\")\n",
    "print(f\"Number of 9s found: {len(nines_indices)}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Time taken: {time_taken:.4f} seconds\")\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553b721",
   "metadata": {},
   "source": [
    "## Find every single digits!\n",
    "## 1 K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab68607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of k-means clustering on the training set: 0.58\n",
      "Time taken: 39.6993 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\AppData\\Local\\Temp\\ipykernel_22876\\2597946184.py:17: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  predicted_labels[mask] = mode(y_train[mask])[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Use k-means clustering with k=10\n",
    "start_time = time.time()  # Start timing\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "kmeans.fit(X_train)\n",
    "end_time = time.time()  # End timing\n",
    "\n",
    "# Get cluster labels for training data\n",
    "cluster_labels_train = kmeans.labels_\n",
    "\n",
    "# Find the most common label in each cluster and assign it as the predicted label\n",
    "predicted_labels = np.zeros_like(cluster_labels_train)\n",
    "for i in range(10):\n",
    "    mask = (cluster_labels_train == i)\n",
    "    predicted_labels[mask] = mode(y_train[mask])[0]\n",
    "\n",
    "# Calculate accuracy on the training set\n",
    "accuracy = accuracy_score(y_train, predicted_labels)\n",
    "\n",
    "# Calculate the time taken in seconds\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(f\"Accuracy of k-means clustering on the training set: {accuracy:.2f}\")\n",
    "print(f\"Time taken: {time_taken:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bc2008",
   "metadata": {},
   "source": [
    "## 2 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c397b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Minkowski distance order 1:\n",
      "Number of 0s found: 1362\n",
      "Number of 1s found: 1704\n",
      "Number of 2s found: 1341\n",
      "Number of 3s found: 1435\n",
      "Number of 4s found: 1284\n",
      "Number of 5s found: 1271\n",
      "Number of 6s found: 1408\n",
      "Number of 7s found: 1535\n",
      "Number of 8s found: 1249\n",
      "Number of 9s found: 1411\n",
      "Accuracy: 0.96\n",
      "Time taken: 205.3257 seconds\n",
      "-------------------------------------\n",
      "Results for Minkowski distance order 2:\n",
      "Number of 0s found: 1364\n",
      "Number of 1s found: 1664\n",
      "Number of 2s found: 1353\n",
      "Number of 3s found: 1434\n",
      "Number of 4s found: 1289\n",
      "Number of 5s found: 1267\n",
      "Number of 6s found: 1407\n",
      "Number of 7s found: 1516\n",
      "Number of 8s found: 1282\n",
      "Number of 9s found: 1424\n",
      "Accuracy: 0.97\n",
      "Time taken: 14.1817 seconds\n",
      "-------------------------------------\n",
      "Results for Minkowski distance order 3:\n",
      "Number of 0s found: 1359\n",
      "Number of 1s found: 1654\n",
      "Number of 2s found: 1357\n",
      "Number of 3s found: 1432\n",
      "Number of 4s found: 1284\n",
      "Number of 5s found: 1267\n",
      "Number of 6s found: 1409\n",
      "Number of 7s found: 1514\n",
      "Number of 8s found: 1295\n",
      "Number of 9s found: 1429\n",
      "Accuracy: 0.97\n",
      "Time taken: 2009.4078 seconds\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Define the Minkowski distance order for k-NN\n",
    "orders = [1, 2, 3]\n",
    "\n",
    "# Loop over each order and train k-NN model\n",
    "for order in orders:\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Train k-NN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, p=order)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy on the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    \n",
    "    # Calculate the time taken in seconds\n",
    "    time_taken = end_time - start_time\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for Minkowski distance order {order}:\")\n",
    "    for digit in range(10):\n",
    "        digit_indices = np.where(y_pred == digit)[0]\n",
    "        print(f\"Number of {digit}s found: {len(digit_indices)}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Time taken: {time_taken:.4f} seconds\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847fed6",
   "metadata": {},
   "source": [
    "## 3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6067b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "C:\\Users\\Kenny\\AppData\\Local\\Temp\\ipykernel_19152\\310482677.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = y.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision Tree:\n",
      "Number of 0s found: 1327\n",
      "Number of 1s found: 1609\n",
      "Number of 2s found: 1329\n",
      "Number of 3s found: 1441\n",
      "Number of 4s found: 1341\n",
      "Number of 5s found: 1256\n",
      "Number of 6s found: 1435\n",
      "Number of 7s found: 1492\n",
      "Number of 8s found: 1344\n",
      "Number of 9s found: 1426\n",
      "Accuracy: 0.87\n",
      "Time taken: 22.1452 seconds\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']\n",
    "y = y.astype(np.int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "    \n",
    "# Train Decision Tree classifier\n",
    "dtree = DecisionTreeClassifier(max_depth=None)\n",
    "dtree.fit(X_train, y_train)\n",
    "    \n",
    "# Predict on the test set\n",
    "y_pred = dtree.predict(X_test)\n",
    "    \n",
    "# Calculate accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "end_time = time.time()  # End timing\n",
    "    \n",
    "# Calculate the time taken in seconds\n",
    "time_taken = end_time - start_time\n",
    "    \n",
    "# Print the results\n",
    "print(f\"Results for Decision Tree:\")\n",
    "for digit in range(10):\n",
    "    digit_indices = np.where(y_pred == digit)[0]\n",
    "    print(f\"Number of {digit}s found: {len(digit_indices)}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Time taken: {time_taken:.4f} seconds\")\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28698af7",
   "metadata": {},
   "source": [
    "## 4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71e9520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "C:\\Users\\Kenny\\AppData\\Local\\Temp\\ipykernel_21604\\1957936470.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = y.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RandomForest:\n",
      "Number of 0s found: 1343\n",
      "Number of 1s found: 1605\n",
      "Number of 2s found: 1414\n",
      "Number of 3s found: 1414\n",
      "Number of 4s found: 1304\n",
      "Number of 5s found: 1254\n",
      "Number of 6s found: 1402\n",
      "Number of 7s found: 1509\n",
      "Number of 8s found: 1348\n",
      "Number of 9s found: 1407\n",
      "Accuracy: 0.97\n",
      "Time taken: 37.1615 seconds\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']\n",
    "y = y.astype(np.int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "    \n",
    "# Train RandomForest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None)\n",
    "rf.fit(X_train, y_train)\n",
    "    \n",
    "# Predict on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "    \n",
    "# Calculate accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "end_time = time.time()  # End timing\n",
    "    \n",
    "# Calculate the time taken in seconds\n",
    "time_taken = end_time - start_time\n",
    "    \n",
    "# Print the results\n",
    "print(f\"Results for RandomForest:\")\n",
    "for digit in range(10):\n",
    "    digit_indices = np.where(y_pred == digit)[0]\n",
    "    print(f\"Number of {digit}s found: {len(digit_indices)}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Time taken: {time_taken:.4f} seconds\")\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a691d5",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb0972",
   "metadata": {},
   "source": [
    "## The accuracies for KNN, decision tree and random forest all appear to be the same for both binary classification and multi-class classification, with slight differences in the computation times. The number of 9s found using binary classification and multi-class classification were identical using KNN (with $k=5$) but were slightly different for decision tree and random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9c272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
